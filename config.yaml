# === MCP-AI v2 â€” PRODUCT CONFIG ===
# Run with:
#   python -m mcp_ai.main --config ./mcp_ai/config.yaml
#
# Design:
# â€¢ FAST pass on everything (cheap) â†’ choose DEEP (expensive) via auto-triggers.
# â€¢ Prefer LOCAL LLMs; stage hard cases for CLOUD with explicit approval.
# â€¢ Emit clean catalog (JSONL + CSV) per-run + global rollup. Structured logs.

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Runtime mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode_selector: prompt
scan_profile: deep

paths:
  roots:
    - "/Users/vamsi_mure/Documents/mcp_ai-v2/mcp_ai/input_files/SampleFiles"
  exclude_globs:
    - "**/.git/**"
    - "**/tmp/**"
    - "**/__pycache__/**"

profiles:
  basic:
    text_extract: true
    ocr: false
    expand_archives: false
    include_types: ["pdf","docx","txt","csv","xlsx","pptx","html"]
    max_file_mb: 50

  standard:
    text_extract: true
    ocr: true
    expand_archives: true
    include_types: ["pdf","docx","txt","csv","xlsx","html","pptx"]
    max_file_mb: 100

  deep:
    text_extract: true
    ocr: true
    expand_archives: true
    include_types: ["*"]
    max_file_mb: 500
    timebox_ocr_s: 30

    detect_language: true
    collect_exif: true
    table_detection: "light"
    text_quality_probe: true

    parse_pdf_order: ["pymupdf", "pdfminer", "pdfplumber", "ocr"]

    # A/V transcription cascade
    av_transcribe_order: ["faster_whisper", "whisper", "demo"]
    av_max_seconds: 0            # 0 = full file; set e.g. 600 to cap at 10 min for speed
    av_chunk_seconds: 600        # split long audio into 10-minute chunks
    av_lang_probe_seconds: 60    # quick probe to guess language

    # OCR cascade
    ocr_engine_order: ["easyocr", "tesseract", "rapidocr", "paddle", "azure"]
    allow_cloud_ocr: false
    ocr_lang: "eng"
    ocr_dpi: 144
    ocr_max_pages: 6

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Type policies (per-extension behavior) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
type_policies:
  skip: [".iso", ".img", ".bin", ".ds_store"]          # Completely skip (no extraction)
  metadata_only: [".psd", ".ai", ".mod"]               # Heavy/unknown formats
  try_text_then_metadata_only: [".pptx", ".xlsx", ".zip"]
  prefer_ocr: [".pdf", ".tiff", ".png", ".jpg", ".jpeg"]

# NOTE: Do NOT include audio/video in metadata_only if you want transcripts:
#   Audio: .mp3, .wav, .m4a, .aac, .flac
#   Video: .mp4, .mov, .mkv

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Domain hints (helps LLM/heuristics) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
domain:
  detect: hybrid
  list: [finance, legal, hr, it, marketing, engineering, operations, healthcare, education, general]
  hints:
    finance:  ["invoice","po","ledger","balance sheet","tax","gst","amount due","net 30","PO"]
    legal:    ["contract","agreement","nda","clause","indemnification","governing law","termination"]
    hr:       ["employee","payroll","benefits","recruiting","onboarding"]
    it:       ["server","api","database","kubernetes","terraform","endpoint","log"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AI enrichment (FAST/DEEP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ai:
  mode: local                    # none | local | cloud
  provider: ollama               # ollama | azure
  fast_pass: true                # run FAST on every doc

  deep:
    policy: auto                 # auto | always | never
    auto_triggers:
      low_confidence_below: 0.90
      contains_pii: true
      high_value_flag: true
    sampling: smart              # smart | full
    pii_redaction: true
    max_chars_fast: 6000
    max_chars_local: 60000
    max_chars_cloud: 120000

  # Local (Ollama) â€” existing config (kept)
  local:
    endpoint: "http://127.0.0.1:11434"
    fast_model: "mistral:7b-instruct"
    deep_model: "qwen2.5:14b-instruct"
    timeout_s: 200
    retries: 3
    backoff_s: 1.2

    # NEW: faster-whisper tuning (kept)
    faster_whisper:
      model: "base"
      device: "cpu"
      compute_type: "int8"
      language: null
      vad_filter: true
      beam_size: 1
      no_speech_threshold: 0.2

  # ---------- UI compatibility bridge ----------
  # These keys make the Streamlit dashboard auto-configure itself
  local:
    endpoint: "http://127.0.0.1:11434"   # (duplicated above for clarity)
    fast_model: "mistral:7b-instruct"
    deep_model: "qwen2.5:14b-instruct"
    timeout_s: 200
    retries: 3
    backoff_s: 1.2
    faster_whisper:
      model: "base"
      device: "cpu"
      compute_type: "int8"
      language: null
      vad_filter: true
      beam_size: 1
      no_speech_threshold: 0.2

    # ğŸ‘‡ NEW sub-block the Streamlit reads
    ollama:
      url: "http://127.0.0.1:11434"
      # pick your preferred default model for Q&A in the UI:
      model: "llama3.1"
      embed_model: "nomic-embed-text"

  cloud:
    enabled: false               # UI will default to local unless you flip this to true
    provider: "azure-openai"     # normalized for the UI: "azure-openai" | "openai" | "none"
    azure:
      api_key: ""                # required if enabled && provider=azure-openai
      endpoint: "https://YOUR-RESOURCE.openai.azure.com"
      deployment: "gpt-4o-mini"
      embed_deployment: "text-embedding-3-small"
    openai:
      api_key: ""
      model: "gpt-4o-mini"
      embed_model: "text-embedding-3-small"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Cloud (Azure OpenAI) â€” pipeline (kept) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cloud:
  provider: "azure"
  endpoint: "https://YOUR-RESOURCE.openai.azure.com"
  api_version: "2024-08-01-preview"
  deployment_fast: "gpt-4o-mini"
  deployment_deep: "gpt-4o"
  timeout_s: 20
  pricing:
    fast_input_per_1k: 0.0005
    fast_output_per_1k: 0.0015
    deep_input_per_1k: 0.0030
    deep_output_per_1k: 0.0060

# Optional: Azure Document Intelligence (OCR) â€” used only if allow_cloud_ocr=true
azure:
  document_intelligence:
    endpoint_env: "AZURE_FORMREC_ENDPOINT"
    key_env: "AZURE_FORMREC_KEY"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Safety & demo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
safety:
  allow_outbound_network: false
  pii_redaction: true

demo:
  enabled: true
  fixture_dir: "./mcp_ai/fixtures"
  simulate_latency_ms: 150

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Budgets / archival â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
budgets:
  run_usd: 25.0
  per_file_usd: 0.03

archival:
  stale_years: 6

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Concurrency / limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
limits:
  max_concurrency_scan: 64
  max_concurrency_extract: 8

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Storage / outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
storage:
  out_root: "./mcp_ai/output_files"
  per_run_outputs: true
  catalog_jsonl: "./mcp_ai/output_files/metadata_catalog.jsonl"
  catalog_csv: "./mcp_ai/output_files/metadata_catalog.csv"
  state_db: "./mcp_ai/output_files/state.sqlite"
  cloud_stage_dir: "./mcp_ai/output_files/cloud_stage"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging:
  level: WARNING
  to_file: true
  file_path: "./mcp_ai/output_files/mcp_ai.log"
  rotate_bytes: 10485760
  backups: 2

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ One-click Scan for UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
scan:
  # This is what the Streamlit "âš™ï¸ Scan" page will run.
  # Adjust to your CLI entry-point if different.
  command: "python -m mcp_ai.main --config ./mcp_ai/config.yaml"