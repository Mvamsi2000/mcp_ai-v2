# === MCP-AI v2 — PRODUCT CONFIG ===
# Run with:
#   python -m mcp_ai.main --config ./mcp_ai/config.yaml
#
# Design:
# • FAST pass on everything (cheap) → choose DEEP (expensive) via auto-triggers.
# • Prefer LOCAL LLMs; stage hard cases for CLOUD with explicit approval.
# • Emit clean catalog (JSONL + CSV) per-run + global rollup. Structured logs.

# ───────────────────────────── Runtime mode ─────────────────────────────
# === MCP-AI v2 — PRODUCT CONFIG ===
mode_selector: prompt
scan_profile: deep

paths:
  roots:
    - "/Users/vamsi_mure/Documents/mcp_ai-v2/mcp_ai/input_files/SampleFiles"
  exclude_globs:
    - "**/.git/**"
    - "**/tmp/**"
    - "**/__pycache__/**"

profiles:
  basic:
    text_extract: true
    ocr: false
    expand_archives: false
    include_types: ["pdf","docx","txt","csv","xlsx","pptx","html"]
    max_file_mb: 50

  standard:
    text_extract: true
    ocr: true
    expand_archives: true
    include_types: ["pdf","docx","txt","csv","xlsx","html","pptx"]
    max_file_mb: 100

  deep:
    text_extract: true
    ocr: true
    expand_archives: true
    include_types: ["*"]
    max_file_mb: 500
    timebox_ocr_s: 40

    detect_language: true
    collect_exif: true
    table_detection: "light"
    text_quality_probe: true

    parse_pdf_order: ["pymupdf", "pdfminer", "pdfplumber", "ocr"]

    # A/V transcription cascade
    av_transcribe_order: ["faster_whisper", "whisper", "demo"]
    av_max_seconds: 0   # 0 = full file; set e.g. 600 to cap at 10 min for speed
    av_chunk_seconds: 600       # split long audio into 10-minute chunks
    av_lang_probe_seconds: 60   # quick probe to guess language



    # OCR cascade
    ocr_engine_order: ["easyocr", "tesseract", "rapidocr", "paddle", "azure"]
    allow_cloud_ocr: false
    ocr_lang: "eng"
    ocr_dpi: 144
    ocr_max_pages: 6
# ───────────────────────────── Type policies (per-extension behavior) ──────────
type_policies:
  # Completely skip (no extraction)
  skip: [".iso", ".img", ".bin", ".ds_store"]

  # Metadata-only (no text/ocr/transcripts) — heavy design/binary or unknown custom
  metadata_only: [".psd", ".ai", ".mod"]   # keep .mod here until a parser is added

  # Try text first; if empty → fall back to metadata-only
  try_text_then_metadata_only: [".pptx", ".xlsx", ".zip"]

  # Prefer OCR for these; PDF still tries text parsers before OCR
  prefer_ocr: [".pdf", ".tiff", ".png", ".jpg", ".jpeg"]

# NOTE: Do NOT include audio/video in metadata_only if you want transcripts:
#   Audio: .mp3, .wav, .m4a, .aac, .flac
#   Video: .mp4, .mov, .mkv

# ───────────────────────────── Domain hints (helps LLM/heuristics) ─────────────
domain:
  detect: hybrid
  list: [finance, legal, hr, it, marketing, engineering, operations, healthcare, education, general]
  hints:
    finance:  ["invoice","po","ledger","balance sheet","tax","gst","amount due","net 30","PO"]
    legal:    ["contract","agreement","nda","clause","indemnification","governing law","termination"]
    hr:       ["employee","payroll","benefits","recruiting","onboarding"]
    it:       ["server","api","database","kubernetes","terraform","endpoint","log"]

# ───────────────────────────── AI enrichment (FAST/DEEP) ───────────────────────
ai:
  mode: local                    # none | local | cloud
  provider: ollama               # ollama | azure
  fast_pass: true                # run FAST on every doc

  deep:
    # When to run DEEP:
    #  • auto   → run only when triggers fire (recommended)
    #  • always → run on every file
    #  • never  → never run
    policy: auto                 # auto | always | never

    # Auto-triggers (used when policy=auto)
    auto_triggers:
      low_confidence_below: 0.90 # if FAST confidence < threshold → DEEP
      contains_pii: true         # if FAST flags PII → DEEP
      high_value_flag: true      # allow caller to force DEEP on specific docs

    sampling: smart              # smart (sample head/tail) | full (entire text)
    confidence_threshold: 0.75   # legacy key still honored where used
    pii_redaction: true
    max_chars_fast: 6000
    max_chars_local: 60000
    max_chars_cloud: 120000

  # Local (Ollama) — pull these models once via `ollama pull <model>`
  local:
    endpoint: "http://127.0.0.1:11434"
    fast_model: "mistral:7b-instruct"
    deep_model: "qwen2.5:14b-instruct"
    timeout_s: 200
    retries: 3
    backoff_s: 1.2
  
  # NEW: A/V transcription tuning for faster-whisper
    faster_whisper:
      model: "base"        # or "tiny.en" for speed
      device: "cpu"        # "cpu" or "cuda" if you have GPU
      compute_type: "int8" # "int8", "int8_float32", "float16", ...
      language: null            # null = auto; "en" to force English      vad_filter: true
      beam_size: 1
      no_speech_threshold: 0.2

# Cloud (Azure OpenAI) — only used if ai.mode=cloud
cloud:
  provider: "azure"
  endpoint: "https://YOUR-RESOURCE.openai.azure.com"
  api_version: "2024-08-01-preview"
  deployment_fast: "gpt-4o-mini"
  deployment_deep: "gpt-4o"
  timeout_s: 20
  pricing:
    fast_input_per_1k: 0.0005
    fast_output_per_1k: 0.0015
    deep_input_per_1k: 0.0030
    deep_output_per_1k: 0.0060

# Optional: Azure Document Intelligence (OCR) — used only if allow_cloud_ocr=true
azure:
  document_intelligence:
    endpoint_env: "AZURE_FORMREC_ENDPOINT"
    key_env: "AZURE_FORMREC_KEY"

# ───────────────────────────── Safety & demo ───────────────────────────────────
safety:
  allow_outbound_network: false   # keep OFF for local-only runs
  pii_redaction: true

demo:
  enabled: true
  fixture_dir: "./mcp_ai/fixtures"
  simulate_latency_ms: 150

# ───────────────────────────── Budgets / archival ──────────────────────────────
budgets:
  run_usd: 25.0
  per_file_usd: 0.03

archival:
  stale_years: 6

# ───────────────────────────── Concurrency / limits ────────────────────────────
limits:
  max_concurrency_scan: 64
  max_concurrency_extract: 8

# ───────────────────────────── Storage / outputs ───────────────────────────────
storage:
  out_root: "./mcp_ai/output_files"
  per_run_outputs: true
  catalog_jsonl: "./mcp_ai/output_files/metadata_catalog.jsonl"
  catalog_csv: "./mcp_ai/output_files/metadata_catalog.csv"
  state_db: "./mcp_ai/output_files/state.sqlite"
  cloud_stage_dir: "./mcp_ai/output_files/cloud_stage"   # suggested files for cloud DEEP

# ───────────────────────────── Logging ─────────────────────────────────────────
logging:
  level: DEBUG                    # DEBUG | INFO | WARNING | ERROR
  to_file: true
  file_path: "./mcp_ai/output_files/mcp_ai.log"
  rotate_bytes: 10485760         # 10 MB
  backups: 3